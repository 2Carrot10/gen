#!/home/twocarrot10/Documents/programs/ollamaWrapper/.venv/bin/python
# change this to match your project dir
import requests
import json
import sys
import argparse
import time
import subprocess
import re

default_ai = "qwen2.5-coder:1.5b"
ai = default_ai

parser = argparse.ArgumentParser(description="""
Run ollama LLMs from the terminal.
""")
parser.add_argument("-a", "--append", action="store_true",
                    help="Append to the end of input")
parser.add_argument("-m", "--model", nargs="?",
                    help="Choose what AI to use. Default")
parser.add_argument("-i", "--input", nargs="?",
                    help="Optionally use instead of inputing through STDIN")
parser.add_argument("-e", "--explain", nargs="?",
                    help="Give info in addition to inputing through STDIN")
parser.add_argument("-q", "--quote", action="store_true",
                    help="Format generated text as a block quote with AI citation.")
parser.add_argument("-l", "--list", action="store_true",
                    help="list all useable AIs")
args = parser.parse_args()

if args.model is not None:
    if args.model == "qwen":
        ai = "qwen2.5-coder:1.5b"
    if args.model == "codellama":
        ai = "codellama:7b"
    elif args.model == "code":
        ai = "codellama:7b-code"
    elif args.model == "phi3":
        ai = "phi3:mini"
    else:
        ai = args.model


def listModels():
    subprocess.run("ollama list", shell=True)


def generate():
    input = ""
    inputAndExplination = ""
    if args.input is None:
        for line in sys.stdin:
            input = input + line
        if args.explain is not None:
            inputAndExplination = args.explain + "\n" + input
        else:
            inputAndExplination = input
    else:
        input = args.input
        inputAndExplination = input  # There is no extra explanation to give

    url = "http://localhost:11434/api/generate"

    data = dict(
        model=ai,
        prompt=inputAndExplination,
        stream=False
    )

    response = requests.post(url=url, json=data)

    output = ""
    text = json.loads(response.text).get("response")
    if args.quote:
        text = re.sub('\n', '\n\t', text)
        text = ">\t" + text
        text = text + f"\n -{ai}"
    if args.append:
        output = output + input + "\n"
    output = output + text
    return output


def tryProc():
    try:
        if args.list:
            listModels()
        else:
            print(generate())
    except Exception:
        print("\n")


process = None

try:
    requests.get(url="http://localhost:11434/")
except Exception:
    subprocess._PopenSelector
    process = subprocess.Popen(['ollama', 'serve'],
                               stdout=subprocess.DEVNULL,
                               stderr=subprocess.DEVNULL)
    while True:
        try:
            requests.get(url="http://localhost:11434/")
            break
        except Exception:
            time.sleep(.01)

tryProc()

if process is not None:
    process.terminate()
    process.wait()
